\section{\hl{Unnamed section}}
\label{sec:conjecture}


\subsection{Observation}

Continuous sensing applications are commonly structured
as modular pipelines of pre-processing steps, followed by a classifier. 
Moreover, while the application logic of different sensing applications
varies widely, applications that use the same sensors tend to make use
of similar algorithms in the early stages of their event detection
pipelines. However, different detection applications or different calibrations
of the same application may run these algorithms with different parameter
configurations. For example, acceleration data has significant noise, and 
hence many applications have implemented low-pass filters to smoothen the accelerometer
readings. In addition, audio data is commonly passed though noise reduction steps to 
remove background noise or through high-cut or
low-cut filters in order to reduce the amount of treble or bass in the
sound.  Image processing makes use of low-pass, high-pass and
band-pass filtering for noise reduction, and edge
detection~\cite{paul2005computer,marr1980theory}.

Feature extraction is another common step for event detection algorithms. 
The features extracted from the sensor data are commonly used for admission
control or by the event classifier. While there exists some overlap, the set
of extracted features generally varies between different sensing applications.

\subsection{Conjecture}

Continuous mobile sensing applications should be structured as a pair of 
classifiers of increasing complexity:  A simple high recall and moderate 
precision classifier that runs continuously on low-power hardware, and acts 
as an energy efficient wakeup mechanism for a higher complexity classifier 
that provides both high recall and high precision, running on the main CPU 
of the device.  

We conjecture: 1) that is possible to implement simple classifiers for a 
wide range of applications by configuring a small set of common pre-processing 
algorithms; and  2) that this approach will achieve comparable energy 
savings to an alternative implementation that support full programmability.

\iffalse

We believe that a small set of pre-processing algorithms and parameter configuration
options would provide coverage of the early pipeline stages for a wide range of continuous
sensing applications. Moving and executing these early pipeline stages on a peripheral
processor contained on the sensor node can allow the main processor to remain asleep for extended periods of time, thus,
significantly reducing energy consumption and making mobile devices a viable platform for
prolonged execution of continuous sensing applications.

\fi

\subsection{Approach}

Our approach makes continuous mobile sensing possible by providing a sensor API
that gives access to configurable pre-processing algorithms running on a low-power
sensor node. Applications construct {\em simple classifiers} for events of interest by 
using a pre-defined set of common pre-processing algorithms and tuning their
parameters.  The {\em simple classifiers} would execute on the low-power sensor node and, 
when events of interest are detected, the main processor is woken up
and the application code is invoked. The result is that applications
view the sensors as ``smart'' sensors that generate relevant events
only. 

\iffalse
	Figure~\ref{fig:smartarchitecture} shows the architecture of a
	system that implements the Smartsensors abstraction.  Applications
	interact with a sensor manager and define custom wake-up conditions by
	choosing among the available pre-defined algorithms.  The figure also
	shows that the architecture supports recognition libraries that
	encapsulate the functionality of the Smartsensor to provide simple
	wake up conditions for a large number of activities.


	\begin{figure}[t]
		\includegraphics[width=3.1in]{android_smartsensor_architecture_proposed.png}
		\caption{Smartsensor system architecture.}
		\label{fig:smartarchitecture}
	\end{figure}
\fi

\subsection{Advantages}

This approach has multiple advantages over the approaches described in
Section~\ref{sec:background}. Programming complexity is decreased because application developers
can use the pre-defined pre-processing algorithms, rather than implementing
them themselves. It also creates predictable performance for the algorithms executed
on the low-power processor. Profiling each algorithm will provide metrics about computational
and time requirements, as well as power consumption. Predictable performance is important in
order to support multiple concurrent classifier executions or 
applications that make use of multiple sensors.

Providing access to these algorithms via an API has significant security
advantages over the fully programmable offloading approach because
application developers cannot execute arbitrary code on the peripheral 
processor. Moreover, it ensures application portability to other
devices featuring this sensing approach. Since the algorithms are pre-specified,
the device manufacturer can optimize their implementations for each
low-power processor, improving application portability between
devices. Furthermore, it is possible to optimize the operation of
multiple applications that use the same algorithms. \hl{Eyal: the same applies to the actual 
sensor as different instances of even the same model a device may use sensors from different manufacturers.}

\subsection{Challenges}

The main challenge with our approach is defining the
appropriate set of algorithms that should be included in the API and 
executed on the low-power processor for each sensor. First, there is a
trade-off between algorithm generality and accuracy.  Simple generic
pre-processing algorithms can support a large set of applications, albeit no specific
application is likely to experience optimal performance.  Conversely, a
highly specialized algorithm may provide optimal performance but is only
applicable to a limited set of applications.  Second, there is also a
trade-off between algorithm complexity and power savings.  More complex
algorithms can reduce energy consumption by preventing unnecessary
wake-ups due to increased accuracy. On the other hand, more complex
algorithms have higher computational demands, which require a larger and
hungrier peripheral processor. A related challenge is determining what data 
the sensor hub should pass to the application
following a wake-up. Some applications may be interested in the raw sensor data, while others
may want to use the filtered data or extracted features. An across-the-board solution would be
to allow the applications to specify what data they are interested in via the API.

We believe application developers may face challenges in selecting the optimal algorithms
and configuration parameters for their {\em simple classifiers}. Given feedback from the application, 
self-learning mechanisms may be able to determine optimal
configuration parameters for the algorithms used. \hl{Ashvin: training could be used} It is easy to imagine an application
notifying the sensor hub about wake-ups when events of interest were not actually detected (i.e. false 
positives). However, it will be more difficult to automatically identify events
of interest missed by the classifier running on the low-power node (i.e. false negatives).

Another challenge lies in supporting multiple concurrent applications while still maintaining
predictable performance. The fully programmable offloading approach has a similar issue
because multiple applications are not able to execute code concurrently on the peripheral
processor. However, given that the algorithms in our approach are pre-defined, they can be
profiled in terms of computational power requirements. A resource manager would be required to orchestrate
and synchronize concurrent requests from multiple applications. This issue also has an impact on the number and sizing of
processors contained by the sensor hub. Each sensor (or small group of related sensors) may be supported by
its own dedicated low-power processor. Alternatively, a slightly bigger processor could be used to serve
the entire sensor hub. Identifying a sweet spot between the maximum number of concurrent
algorithm executions, energy budget, cost and physical size of the sensor node is an avenue for future work.

\hl{TODO: describe challenge in supporting applications interested in the multiple sensors (sensor fusion)}